{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb7qyhNL1yWt"
   },
   "source": [
    "# On-device recommendations with Firebase ML and TensorFlow Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyYiyNxVp6mS"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CShg7PXmqGUJ"
   },
   "source": [
    "This code base provides a toolkit to train an on-device recommendation\n",
    "tensorflow model with user data collected in your app with Firebase Analytics. This model will then be deployed with Firebase ML to serve movie recommendations in the sample app FireFlix.\n",
    "\n",
    "This Notebook shows an end-to-end example that 1) imports Firebase Analytics data from BigQuery 2) preprocesses that data to prepare it for training 3) trains a recommendations model using the data and 4) exports the model in tflite format, ready to use in apps to run inference and serve recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcLF2PKkSbV3"
   },
   "source": [
    "The model uses a Convolutional neural-network encoder (CNN): applying multiple layers of convolutional neural-network to generate an encoding of the user history analytics data. For more details, refer to the [documentation]() for the underlying tensorflow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cv3K3oaksJv",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/arjunnrajput/Smart-ML-Based-Movie-Recommendation-System/ml\n",
    "!pip install -r requirements.txt\n",
    "!pip install --upgrade google-cloud-storage google-cloud-bigquery[bqstorage]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joSTkeEWN01m"
   },
   "source": [
    "## Set up authentication\n",
    "\n",
    "In this notebook, we use analytics data from BigQuery to generate training data for our recommendations model. To access BigQuery data from the Colab notebook, you need to upload the service account file that you have downloaded.\n",
    "\n",
    "Note: If this step is throwing an error, you can either:\n",
    "1. Manually upload the json file to the /content folder using the Folder icon in the left menu. Then set the GOOGLE_APPLICATION_CREDENTIALS environment variable to the file path.\n",
    "i.e. If file was uploaded to /content, run:\n",
    "`os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/content/<your_service_acct_file_name>`\n",
    "OR,\n",
    "2. Try disabling third party cookies in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqN2Qro5sN5f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "  with open('/content/' + fn, 'wb') as f:\n",
    "    f.write(uploaded[fn])\n",
    "  os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]='/content/' + fn\n",
    "  projectID = fn.rsplit(\"-\", 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4dy0D_RQK2D"
   },
   "source": [
    "# Import app analytics data from BigQuery\n",
    "\n",
    "In this step, we will load the analytics data we collected in the app with Firebase Analytics and sent to BigQuery. We will load the data into the pandas data processing library and then preprocess this data to be the appropriate format for input for the model training step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUc7uJXMRLNb"
   },
   "source": [
    "## Enable BigQuery IPython magics\n",
    "\n",
    "BigQuery provides several convenience IPython magics that we will use to fetch data with the %load_ext magic below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5J2plSCksN5h"
   },
   "outputs": [],
   "source": [
    "%reload_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pq46MEB5RlUR"
   },
   "source": [
    "## Import data\n",
    "\n",
    "We use the following SQL statement to get items from the table we created in BigQuery. Firebase Analytics exports a lot of additional information, such as device type, platform version, etc, that we don't need for the purposes of training this model. Initially, we only get a limited amount of rows to briefly explore the form of this data and select which fields are important.\n",
    "\n",
    "Notice that a row in the dataframe is created for each analytics event logged in the app. This row has many properties, but the ones that are of importance for this notebook are the fields:\n",
    "* event_name\n",
    "* event_timestamp\n",
    "* items\n",
    "* user_pseudo_id\n",
    "\n",
    "Notice that some fields, such as the **items** field is actually an object. We will extract the subfield of interest below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoAKLXkZsN5j"
   },
   "outputs": [],
   "source": [
    "%%bigquery analytics_test_import\n",
    "SELECT\n",
    "    *\n",
    "FROM `firebase_recommendations_dataset.recommendations_table`\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLXfzEckVMZ1"
   },
   "outputs": [],
   "source": [
    "analytics_test_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wysL9g8WW5U"
   },
   "source": [
    "All of the columns included in each analytics event entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9jHxMTqU8E2"
   },
   "outputs": [],
   "source": [
    "analytics_test_import.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImvkOzFwWQN4"
   },
   "source": [
    "Of the information logged under 'items', we are only interested in 'item_id',which corresponds to the ID of the movie the user interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVazzlpLVwTN"
   },
   "outputs": [],
   "source": [
    "analytics_test_import['items'][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HF3vnWJXThab"
   },
   "source": [
    "Now we run the following command to import the whole dataset into a variable. Note how we only import the fields which we are interested in for training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXK2PAK5AMpM"
   },
   "outputs": [],
   "source": [
    "%%bigquery analytics_data_real\n",
    "SELECT\n",
    "    items,user_pseudo_id,event_timestamp\n",
    "FROM `firebase_recommendations_dataset.recommendations_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdM67AvOsN5p"
   },
   "outputs": [],
   "source": [
    "analytics_data_real.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTdiPeVjUADI"
   },
   "source": [
    "# Preprocess the dataset\n",
    "\n",
    "In this step, we create a lambda function to extract a subfield 'item_id' from the items object. This represents the movie_id, so we also rename the columns to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJzJb0AsDQlk"
   },
   "outputs": [],
   "source": [
    "analytics = analytics_data_real\n",
    "def getMovieID(row):\n",
    "  items_obj = row['items'][0]\n",
    "  return items_obj['item_id']\n",
    "analytics['movie_id'] = analytics.apply(lambda row: getMovieID(row), axis=1)\n",
    "analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXi0XmaJUff6"
   },
   "source": [
    "We drop the 'items' column since we don't need anything else from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hUZGrBhErs9"
   },
   "outputs": [],
   "source": [
    "analytics.rename(columns={'user_pseudo_id': 'user_id', 'event_timestamp': 'timestamp'}, inplace=True)\n",
    "analytics.drop(['items'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQW3-22MUnrH"
   },
   "source": [
    "Here is our processed dataframe containing only the data we want to use in training.\n",
    "\n",
    "The data has the following properties:\n",
    "*   UserIDs range between 1 and 6040\n",
    "*   MovieIDs range between 1 and 3952\n",
    "*   Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "*   Each user has at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8S7hp8FFxg6"
   },
   "outputs": [],
   "source": [
    "analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS2IXA2IW2Xd"
   },
   "source": [
    "## Sort and group training data to create training examples\n",
    "\n",
    "Our analytics events need to be reorganized in the format required for the model training step. We will create an object that maps key user_id to a list of movies that user has seen. We use the timestamp data to create the sequential context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2gKMD_4sN57"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def convert_to_timelines(df):\n",
    "  \"\"\"Convert ratings data to user.\"\"\"\n",
    "  timelines = collections.defaultdict(list)\n",
    "  movie_counts = collections.Counter()\n",
    "  for user_id, timestamp, movie_id in df.values:\n",
    "    timelines[user_id].append([movie_id, int(timestamp)])\n",
    "    movie_counts[movie_id] += 1\n",
    "  # Sort per-user timeline by timestamp\n",
    "  for (user_id, timeline) in timelines.items():\n",
    "    timeline.sort(key=lambda x: x[1])\n",
    "    timelines[user_id] = [movie_id for movie_id, _ in timeline]\n",
    "  return timelines, movie_counts\n",
    "timelines, counts = convert_to_timelines(analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0ASLyOYZqCH"
   },
   "source": [
    "The timelines object contains a list of movie_id's keyed on user_id to indicate the sequence of movies that user has interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6Zm23tgsN59"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "for key, val in sorted(timelines.items())[0:10]:\n",
    "  print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcxmkcOzZ7Zj"
   },
   "source": [
    "## Generate training examples\n",
    "\n",
    "We use the timelines data to generate tensorflow training examples. We discard any timeline with less than 3 context items, and we consider context lengths of 100 items. We perform the following steps:\n",
    "\n",
    "* Groups movie records by user, and orders per-user movie records by timestamp.\n",
    "* Generates Tensorflow examples with features: 1) \"context\": time-ordered sequential movie IDs 2) \"label\": next movie ID user viewed as label. \"max_history_length\" is taken in as parameter to define \"context\" feature shape, if not enough history found, right padding with out-of-vocab ID 0 will be performed.\n",
    "* Then partition the available data into a training and test set.\n",
    "\n",
    "Sample generated training example with max user history as 10:\n",
    "```\n",
    "0 : {   # (tensorflow.Example)\n",
    "  features: {   # (tensorflow.Features)\n",
    "    feature: {\n",
    "      key  : \"context\"\n",
    "      value: {\n",
    "        int64_list: {\n",
    "          value: [ 595, 2687, 745, 588, 1, 2355, 2294, 783, 1566, 1907 ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    feature: {\n",
    "      key  : \"label\"\n",
    "      value: {\n",
    "        int64_list: {\n",
    "          value: [ 48 ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwWgd41asN5_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# used to pad when user doesn't have enough context\n",
    "OOV_MOVIE_ID = 0\n",
    "\n",
    "def generate_examples_from_timelines(timelines,\n",
    "                                     min_timeline_len=3,\n",
    "                                     max_context_len=100):\n",
    "  \"\"\"Convert user timelines to tf examples.\n",
    "\n",
    "  Convert user timelines to tf examples by adding all possible context-label\n",
    "  pairs in the examples pool.\n",
    "\n",
    "  Args:\n",
    "    timelines: the user timelines to process.\n",
    "    min_timeline_len: minimum length of the user timeline.\n",
    "    max_context_len: maximum length of context signals.\n",
    "\n",
    "  Returns:\n",
    "    train_examples: tf example list for training.\n",
    "    test_examples: tf example list for testing.\n",
    "  \"\"\"\n",
    "  train_examples = []\n",
    "  test_examples = []\n",
    "  for timeline in timelines.values():\n",
    "    # Skip if timeline is shorter than min_timeline_len.\n",
    "    if len(timeline) < min_timeline_len:\n",
    "      continue\n",
    "    for label_idx in range(1, len(timeline)):\n",
    "      start_idx = max(0, label_idx - max_context_len)\n",
    "      context = timeline[start_idx:label_idx]\n",
    "      # Pad context with out-of-vocab movie id 0.\n",
    "      while len(context) < max_context_len:\n",
    "        context.append(OOV_MOVIE_ID)\n",
    "      label = timeline[label_idx]\n",
    "      feature = {\n",
    "          \"context\":\n",
    "              tf.train.Feature(int64_list=tf.train.Int64List(value=context)),\n",
    "          \"label\":\n",
    "              tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "      }\n",
    "      tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "      if label_idx == len(timeline) - 1:\n",
    "        test_examples.append(tf_example.SerializeToString())\n",
    "      else:\n",
    "        train_examples.append(tf_example.SerializeToString())\n",
    "  return train_examples, test_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3v0XcJ3OsN6A"
   },
   "outputs": [],
   "source": [
    "train_examples, test_examples = generate_examples_from_timelines(timelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SS4ZYJCjRvO"
   },
   "source": [
    "Write examples to tfrecords, to be loaded in the model training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVOe4EXUeyjw"
   },
   "outputs": [],
   "source": [
    "def write_tfrecords(tf_examples, filename):\n",
    "  \"\"\"Write tf examples to tfrecord file.\"\"\"\n",
    "  with tf.io.TFRecordWriter(filename) as file_writer:\n",
    "    for example in tf_examples:\n",
    "      file_writer.write(example)\n",
    "\n",
    "output_dir = 'data/examples'\n",
    "OUTPUT_TRAINING_DATA_FILENAME = \"train_movielens_1m.tfrecord\"\n",
    "OUTPUT_TESTING_DATA_FILENAME = \"test_movielens_1m.tfrecord\"\n",
    "\n",
    "if not tf.io.gfile.exists(output_dir):\n",
    "  tf.io.gfile.makedirs(output_dir)\n",
    "write_tfrecords(\n",
    "    tf_examples=train_examples,\n",
    "    filename=os.path.join(output_dir, OUTPUT_TRAINING_DATA_FILENAME))\n",
    "write_tfrecords(\n",
    "    tf_examples=test_examples,\n",
    "    filename=os.path.join(output_dir, OUTPUT_TESTING_DATA_FILENAME))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQcQ6AssuBN8"
   },
   "source": [
    "# Train model\n",
    "\n",
    "The training launcher script uses TensorFlow keras compile/fit APIs and starts training and evaluation process:\n",
    "\n",
    "### Training time / size\n",
    "\n",
    "Another consideration is training time. Rnn generally requires the longer training times, followed by cnn, and finally bow with the shortest training times. Bag of words will also be a smaller sized model if space is a consideration.\n",
    "\n",
    "To start training, execute the following command. Please note that we are using a very small number of epochs (**num_epochs** parameter below) of 10 to speed up training time at the expense of model quality. Generating a high quality model often requires a much higher number. For this model, setting num_epochs to at least 100 should provide a model of sufficient quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gPKz5InxEbF"
   },
   "outputs": [],
   "source": [
    "!python -m model.recommendation_model_launcher_keras \\\n",
    "  --run_mode \"train_and_eval\" \\\n",
    "  --encoder_type \"cnn\" \\\n",
    "  --training_data_filepattern \"data/examples/train_movielens_1m.tfrecord\" \\\n",
    "  --testing_data_filepattern \"data/examples/test_movielens_1m.tfrecord\" \\\n",
    "  --model_dir \"model/model_dir\" \\\n",
    "  --params_path \"model/sample_config.json\"\\\n",
    "  --batch_size 64 \\\n",
    "  --learning_rate 0.1 \\\n",
    "  --steps_per_epoch 1000 \\\n",
    "  --num_epochs 10 \\\n",
    "  --num_eval_steps 1000 \\\n",
    "  --gradient_clip_norm 1.0 \\\n",
    "  --max_history_length 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObH_mcGcxS96"
   },
   "source": [
    "# Export model\n",
    "\n",
    "Now we export the trained model to a tflite file suitable for on-device inference on mobile devices.\n",
    "Note that here we use the latest checkpoint, number 10000 in the **checkpoint_path**. This results from num_epochs (10) x steps_per_epoch (1000). If you change either parameter in the previous training step, you should update this parameter to accordingly export the latest checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SH5r6AxHzGrS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m model.recommendation_model_launcher_keras \\\n",
    "  --run_mode \"export\" \\\n",
    "  --encoder_type \"cnn\" \\\n",
    "  --params_path \"model/sample_config.json\"\\\n",
    "  --model_dir \"model/model_dir\" \\\n",
    "  --checkpoint_path \"model/model_dir/ckpt-10000\" \\\n",
    "  --num_predictions 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXMQ5D5JzSgv"
   },
   "source": [
    "# Model inference (Optional)\n",
    "\n",
    "You could verify your model's performance by running inference with test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "og0qkYavz3Nt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Use [0, 1, ... 9] as example input to represent 10 movies that user interacted with.\n",
    "#context = [1196, 1210, 2628]\n",
    "# context = tf.range(10)\n",
    "context = tf.constant([1196, 1210, 2628, 260, 480, 2571, 589, 1240, 1, 10])\n",
    "\n",
    "# Directory to exported TensorFlow Lite model.\n",
    "export_dir = \"model/model_dir/export\"\n",
    "tflite_model_path = os.path.join(export_dir, 'model.tflite')\n",
    "f = open(tflite_model_path, 'rb')\n",
    "interpreter = tf.lite.Interpreter(model_content=f.read())\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "print(output_details)\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], context)\n",
    "interpreter.invoke()\n",
    "tflite_top_predictions_ids = interpreter.get_tensor(\n",
    "    output_details[0]['index'])\n",
    "tflite_top_prediction_scores = interpreter.get_tensor(\n",
    "    output_details[1]['index'])\n",
    "print(\"results >>>>>\")\n",
    "print(\"input >>>>>\")\n",
    "print(input_details[0])\n",
    "print(\"output >>>>>\")\n",
    "print(tflite_top_predictions_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_omMjoT035u"
   },
   "source": [
    "# Deploy model to the Firebase Console\n",
    "\n",
    "We now deploy the model to the Firebase Console. From there, it can be automatically downloaded to your user's devices with Firebase ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awx9Q73aFyfS"
   },
   "source": [
    "Step 1. Initialize Firebase App Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxHAv1OaNo-X"
   },
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "\n",
    "firebase_admin.initialize_app(options={'projectId': projectID,\n",
    "             'storageBucket': projectID + '.appspot.com' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PxvbLcNNoxZ"
   },
   "source": [
    "Step 2. Upload the model file to Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WPegXrvdnth"
   },
   "outputs": [],
   "source": [
    "from firebase_admin import ml\n",
    "\n",
    "# This uploads it to your bucket as recommendation.tflite\n",
    "source = ml.TFLiteGCSModelSource.from_saved_model(export_dir, 'model.tflite')\n",
    "print (source.gcs_tflite_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjUgFOCCF4Ro"
   },
   "source": [
    "Step 3. Deploy the model to Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbPwOU1iF75O"
   },
   "outputs": [],
   "source": [
    "# Create a Model Format\n",
    "model_format = ml.TFLiteFormat(model_source=source)\n",
    "\n",
    "# Create a Model object\n",
    "sdk_model_1 = ml.Model(display_name=\"recommendations\", model_format=model_format)\n",
    "\n",
    "# Make the Create API call to create the model in Firebase\n",
    "firebase_model_1 = ml.create_model(sdk_model_1)\n",
    "print(firebase_model_1.as_dict())\n",
    "\n",
    "# Publish the model\n",
    "model_id = firebase_model_1.model_id\n",
    "firebase_model_1 = ml.publish_model(model_id)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Firebase ML on-device recommentations.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
